{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIP Framework training example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `/z1-josemm/josemm/MyDocs/personal_BIP/BIPs.jl`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"..\")\n",
    "using BIPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics\n",
    "using Pkg.Artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets begin by bringing in the dataset. It contains tree splits:\n",
    "* **train**: the training set with 1M jets\n",
    "* **validation**: the validation set with 400k jets\n",
    "\n",
    "And of course later we will use the **test** set with other 400k jets to report the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"../../../DataLake/raw/val.h5\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_path = \"../../../DataLake/raw\"\n",
    "# dataset_path = \"/Users/ortner/datasets/toptagging\"\n",
    "\n",
    "train_data_path = dataset_path*\"/train.h5\"\n",
    "val_data_path = dataset_path*\"/val.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data\n",
    "\n",
    "In order to read the datasets, we call the `read_dataset` function:\n",
    "to read the TopQuark format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries in the training data: 1210997"
     ]
    }
   ],
   "source": [
    "train_jets, train_labels = BIPs.read_data(\"TQ\", train_data_path)\n",
    "train_labels = [reinterpret(Bool, b == 1.0) for b in train_labels]\n",
    "print(\"Number of entries in the training data: \", length(train_jets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries in the validation data: 402999"
     ]
    }
   ],
   "source": [
    "val_jets, val_labels = BIPs.read_data(\"TQ\", val_data_path)\n",
    "val_labels = [reinterpret(Bool, b == 1.0) for b in val_labels]\n",
    "print(\"Number of entries in the validation data: \", length(val_jets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets examine how one of the jets looks like, each one of the entries is one detected particle's four momentum $(E, p_x, p_y, p_z)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However,in order to compute the embeddings, it is necesary to convert the jets to a format that can be used by the framework. The function `data2hyp` allows to convert each detected four momentum to the jet basis, a.k.a $(\\tilde p_T, \\cos(\\theta), \\sin(\\theta), \\tilde y, E_T)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed jets\n"
     ]
    }
   ],
   "source": [
    "train_transf_jets = data2basis(train_jets; basis=\"hyp\")\n",
    "val_transf_jets = data2basis(val_jets; basis=\"hyp\")\n",
    "println(\"Transformed jets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the jets are converted to the jet basis, it is moment to embed the model using the *Invariant Polynomials*. \n",
    "\n",
    "The function `build_ip` allocates efficiently the sparse basis, while the `bip_data` computes the invariant representation of each one of the jets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: build_ip not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: build_ip not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/MyDocs/personal_BIP/BIPs.jl/examples/basis_saving.ipynb:1"
     ]
    }
   ],
   "source": [
    "f_bip, specs, a_basis = build_ip(order=2, levels=5)\n",
    "    \n",
    "function bip_data(dataset_jets)\n",
    "    storage = zeros(length(dataset_jets), length(specs))\n",
    "    for i = 1:length(dataset_jets)\n",
    "        storage[i, :] = f_bip(dataset_jets[i])\n",
    "    end\n",
    "    storage[:, 2:end]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596-element Vector{Int64}:\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " â‹®\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded train jets correclty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded test jets correclty\n"
     ]
    }
   ],
   "source": [
    "train_embedded_jets = bip_data(train_transf_jets)\n",
    "println(\"Embedded train jets correclty\")\n",
    "val_embedded_jets = bip_data(val_transf_jets)\n",
    "println(\"Embedded test jets correclty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "length(specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a classifier model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embeddings are now created for the dataset. From this point on, the classification itself is absolutelly versatile. For this specific example we will use the out-of-the box classifier `sklearn.linear_model.HistGradientBoostingClassifier` that bines the data and then applies a grandient boosted trees algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets fit a simple model to the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyCall\n",
    "@pyimport sklearn.ensemble as sk_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GCT = sk_ensemble.HistGradientBoostingClassifier(verbose=false, max_iter=3000, l2_regularization=0.02, learning_rate=0.02, max_depth = 4).fit(train_embedded_jets, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lest test how we do performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we understanad the framework, lets see how our model performs on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"../../../DataLake/raw/test.h5\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data_path = \"../../../DataLake/raw/test.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded test jets correclty"
     ]
    }
   ],
   "source": [
    "test_jets, test_labels = BIPs.read_data(\"TQ\", test_data_path)\n",
    "test_labels = [reinterpret(Bool, b == 1.0) for b in test_labels]\n",
    "test_transf_jets = data2basis(test_jets; basis=\"hyp\")\n",
    "test_embedded_jets = bip_data(test_transf_jets)\n",
    "print(\"Embedded test jets correclty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: GCT not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: GCT not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/MyDocs/personal_BIP/BIPs.jl/examples/basis_saving.ipynb:1"
     ]
    }
   ],
   "source": [
    "test_preds = GCT.score(test_embedded_jets, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DelimitedFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "writedlm( \"/home/josemm/MyDocs/personal_BIP/BIPs.jl/foo/storage_basis/specs.csv\",  specs, ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "writedlm( \"/home/josemm/MyDocs/personal_BIP/BIPs.jl/foo/storage_basis/train_basis.csv\",  train_embedded_jets, ',')\n",
    "writedlm( \"/home/josemm/MyDocs/personal_BIP/BIPs.jl/foo/storage_basis/train_labels.csv\",  train_labels, ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "writedlm( \"/home/josemm/MyDocs/personal_BIP/BIPs.jl/foo/storage_basis/val_basis.csv\",  val_embedded_jets, ',')\n",
    "writedlm( \"/home/josemm/MyDocs/personal_BIP/BIPs.jl/foo/storage_basis/val_labels.csv\",  val_labels, ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "writedlm( \"/home/josemm/MyDocs/personal_BIP/BIPs.jl/foo/storage_basis/test_basis.csv\",  test_embedded_jets, ',')\n",
    "writedlm( \"/home/josemm/MyDocs/personal_BIP/BIPs.jl/foo/storage_basis/test_labels.csv\",  test_labels, ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{BIPs.BiPolynomials.Modules.ASpec}:\n",
       " BIPs.BiPolynomials.Modules.ASpec(1, 0, 0)\n",
       " BIPs.BiPolynomials.Modules.ASpec(1, 0, 0)\n",
       " BIPs.BiPolynomials.Modules.ASpec(0, 0, 0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a_basis.spec[[6,6,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed1560bd249103eb874556eada0ab548e2eb318ac2260e7986d2cded9b278337"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
